#!/bin/bash
start=`date +%s`
hadoop jar /usr/local/hadoop-1.2.1/contrib/streaming/hadoop-streaming-1.2.1.jar -input step1input -output step1output -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/1410351028671taxonomy.xml#1410351028671taxonomy.xml -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/1410351028671capercloud_test.mgf.xml#1410351028671capercloud_test.mgf.xml -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/mrtandem#mrtandem -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/default_input.xml#default_input.xml -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/chr1_six_7.fa#chr1_six_7.fa -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/capercloud_test.mgf#capercloud_test.mgf -mapper "mrtandem -mapper1_1 hdfs://172.31.41.89:9000/user/ubuntu/ 1410351028671capercloud_test.mgf.xml" -reducer "mrtandem -reducer1_1 hdfs://172.31.41.89:9000/user/ubuntu/ 1410351028671capercloud_test.mgf.xml" -jobconf mapred.task.timeout=36000000 -jobconf mapred.reduce.tasks=1 -jobconf mapred.map.tasks=2 -jobconf mapred.reduce.tasks.speculative.execution=false -jobconf mapred.map.tasks.speculative.execution=false
stop=`date +%s`
echo "*******Step 1 running time: $[ stop - start ]s*******"
start=`date +%s`
hadoop jar /usr/local/hadoop-1.2.1/contrib/streaming/hadoop-streaming-1.2.1.jar -input step1output -output step2output -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/1410351028671taxonomy.xml#1410351028671taxonomy.xml -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/1410351028671capercloud_test.mgf.xml#1410351028671capercloud_test.mgf.xml -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/mrtandem#mrtandem -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/default_input.xml#default_input.xml -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/chr1_six_7.fa#chr1_six_7.fa -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/capercloud_test.mgf#capercloud_test.mgf -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/reducer1_1#reducer1_1 -mapper "mrtandem -mapper2_1 hdfs://172.31.41.89:9000/user/ubuntu/ 1410351028671capercloud_test.mgf.xml" -reducer "mrtandem -reducer2_1 hdfs://172.31.41.89:9000/user/ubuntu/ 1410351028671capercloud_test.mgf.xml" -jobconf mapred.task.timeout=36000000 -jobconf mapred.reduce.tasks=1 -jobconf mapred.map.tasks=2 -jobconf mapred.reduce.tasks.speculative.execution=false -jobconf mapred.map.tasks.speculative.execution=false
stop=`date +%s`
echo "*******Step 2 running time: $[ stop - start ]s*******"
start=`date +%s`
hadoop jar /usr/local/hadoop-1.2.1/contrib/streaming/hadoop-streaming-1.2.1.jar -input step2output -output step3output -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/1410351028671taxonomy.xml#1410351028671taxonomy.xml -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/1410351028671capercloud_test.mgf.xml#1410351028671capercloud_test.mgf.xml -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/mrtandem#mrtandem -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/default_input.xml#default_input.xml -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/chr1_six_7.fa#chr1_six_7.fa -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/shared/capercloud_test.mgf#capercloud_test.mgf -cacheFile hdfs://172.31.41.89:9000/user/ubuntu/reducer2_1#reducer2_1 -mapper "mrtandem -mapper3_1 hdfs://172.31.41.89:9000/user/ubuntu/ 1410351028671capercloud_test.mgf.xml" -reducer "mrtandem -reducer3_1 hdfs://172.31.41.89:9000/user/ubuntu/ 1410351028671capercloud_test.mgf.xml -reportURL hdfs://172.31.41.89:9000/user/ubuntu/" -jobconf mapred.task.timeout=36000000 -jobconf mapred.reduce.tasks=1 -jobconf mapred.map.tasks=2 -jobconf mapred.reduce.tasks.speculative.execution=false -jobconf mapred.map.tasks.speculative.execution=false
stop=`date +%s`
echo "*******Step 3 running time: $[ stop - start ]s*******"
hadoop dfs -copyToLocal output output
